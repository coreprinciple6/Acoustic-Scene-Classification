{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  2000  files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'sample audio'\n",
    "\n",
    "metadata = pd.read_csv('esc50.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),str(row[\"filename\"]))\n",
    "    \n",
    "    class_label = row[\"category\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following is the CNN model. 1st input layer: (40,216,1), activation: Relu, Kernal filter zixe: (2x2), dropout: 20%, output layer: 50 nodes because there are 50 classes. last layer will be dense layer with softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 216\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 215, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 106, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 52, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 25, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "=================================================================\n",
      "Total params: 49,762\n",
      "Trainable params: 49,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "400/400 [==============================] - 1s 2ms/step\n",
      "Pre-training accuracy: 2.5000%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2823 - accuracy: 0.9000 - val_loss: 2.5928 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.59283, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2469 - accuracy: 0.9212 - val_loss: 2.5606 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.59283 to 2.56055, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 0.2626 - accuracy: 0.9175 - val_loss: 2.4458 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.56055 to 2.44581, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2480 - accuracy: 0.9169 - val_loss: 2.4432 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.44581 to 2.44319, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 0.2383 - accuracy: 0.9150 - val_loss: 2.4609 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.44319\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2401 - accuracy: 0.9256 - val_loss: 2.5837 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.44319\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 0.2371 - accuracy: 0.9225 - val_loss: 2.5237 - val_accuracy: 0.5550\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.44319\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2357 - accuracy: 0.9225 - val_loss: 2.5699 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.44319\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2263 - accuracy: 0.9262 - val_loss: 2.4560 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.44319\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2271 - accuracy: 0.9244 - val_loss: 2.5018 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.44319\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2243 - accuracy: 0.9287 - val_loss: 2.5817 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.44319\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2048 - accuracy: 0.9294 - val_loss: 2.5985 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.44319\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2253 - accuracy: 0.9337 - val_loss: 2.6939 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.44319\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2254 - accuracy: 0.9206 - val_loss: 2.6405 - val_accuracy: 0.5550\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.44319\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2401 - accuracy: 0.9225 - val_loss: 2.6040 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.44319\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2300 - accuracy: 0.9244 - val_loss: 2.6100 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.44319\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2056 - accuracy: 0.9306 - val_loss: 2.7101 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.44319\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1863 - accuracy: 0.9450 - val_loss: 2.5374 - val_accuracy: 0.5950\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.44319\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1938 - accuracy: 0.9356 - val_loss: 2.6508 - val_accuracy: 0.5625\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.44319\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1934 - accuracy: 0.9362 - val_loss: 2.8249 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.44319\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1999 - accuracy: 0.9394 - val_loss: 2.5759 - val_accuracy: 0.5775\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.44319\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1978 - accuracy: 0.9281 - val_loss: 2.7003 - val_accuracy: 0.5650\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.44319\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1856 - accuracy: 0.9362 - val_loss: 2.7452 - val_accuracy: 0.5450\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.44319\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1904 - accuracy: 0.9406 - val_loss: 2.5323 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.44319\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1670 - accuracy: 0.9400 - val_loss: 2.5711 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.44319\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1809 - accuracy: 0.9475 - val_loss: 2.6120 - val_accuracy: 0.6050\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.44319\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2017 - accuracy: 0.9356 - val_loss: 2.6093 - val_accuracy: 0.5800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.44319\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2051 - accuracy: 0.9344 - val_loss: 2.6918 - val_accuracy: 0.5925\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.44319\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1980 - accuracy: 0.9319 - val_loss: 2.6955 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.44319\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1869 - accuracy: 0.9394 - val_loss: 2.5131 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.44319\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1651 - accuracy: 0.9469 - val_loss: 2.6989 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.44319\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1811 - accuracy: 0.9419 - val_loss: 2.8030 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.44319\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.2159 - accuracy: 0.9306 - val_loss: 2.6436 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.44319\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.2054 - accuracy: 0.9406 - val_loss: 2.7630 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.44319\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1808 - accuracy: 0.9356 - val_loss: 2.7662 - val_accuracy: 0.5725\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.44319\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1811 - accuracy: 0.9381 - val_loss: 2.6074 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.44319\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1738 - accuracy: 0.9413 - val_loss: 2.7399 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.44319\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1622 - accuracy: 0.9488 - val_loss: 2.7101 - val_accuracy: 0.6025\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.44319\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1619 - accuracy: 0.9488 - val_loss: 2.7104 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.44319\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1863 - accuracy: 0.9419 - val_loss: 2.6967 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.44319\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1759 - accuracy: 0.9381 - val_loss: 2.9398 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.44319\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1748 - accuracy: 0.9381 - val_loss: 2.8474 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.44319\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1738 - accuracy: 0.9344 - val_loss: 2.8076 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.44319\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1926 - accuracy: 0.9375 - val_loss: 2.8819 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.44319\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 7s 5ms/step - loss: 0.1855 - accuracy: 0.9400 - val_loss: 2.7732 - val_accuracy: 0.5775\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.44319\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1800 - accuracy: 0.9400 - val_loss: 2.8635 - val_accuracy: 0.5775\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.44319\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1708 - accuracy: 0.9456 - val_loss: 2.7412 - val_accuracy: 0.5875\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.44319\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1621 - accuracy: 0.9469 - val_loss: 2.8153 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.44319\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1648 - accuracy: 0.9481 - val_loss: 2.8714 - val_accuracy: 0.5700\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.44319\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 0.1770 - accuracy: 0.9444 - val_loss: 2.8703 - val_accuracy: 0.5850\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.44319\n",
      "Training completed in time:  0:06:16.276303\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 40\n",
    "#num_batch_size = 128 \n",
    "#test acc: 58.2%\n",
    "\n",
    "num_epochs = 50\n",
    "num_batch_size = 128\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9893749952316284\n",
      "Testing Accuracy:  0.5849999785423279\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for prediction on new wav files\n",
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6920 into shape (1,40,216,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ad6df78180e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'validation audio/siren.wav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# need a wav file with (40,2016,1) for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-a46f3b70c9de>\u001b[0m in \u001b[0;36mprint_prediction\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprediction_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprediction_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 6920 into shape (1,40,216,1)"
     ]
    }
   ],
   "source": [
    "filename = 'validation audio/siren.wav'\n",
    "print_prediction(filename) \n",
    "# need a wav file with (40,2016,1) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
